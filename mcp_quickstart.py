"""
LangChain MCP Adapters å¿«é€Ÿå…¥é—¨ç¤ºä¾‹

è¿™æ˜¯ä¸€ä¸ªæœ€ç®€å•çš„ç¤ºä¾‹ï¼Œå±•ç¤ºå¦‚ä½•ä½¿ç”¨ langchain-mcp-adapters è°ƒç”¨ MCP æœåŠ¡
"""

import asyncio
import os

from langchain.agents import AgentExecutor, create_tool_calling_agent
from langchain_core.prompts import ChatPromptTemplate
from langchain_mcp_adapters.client import create_mcp_client
from langchain_openai import ChatOpenAI


async def quickstart():
    """å¿«é€Ÿå…¥é—¨ç¤ºä¾‹"""

    # 1. é…ç½® API å¯†é’¥ï¼ˆè¯·æ›¿æ¢ä¸ºä½ çš„å®é™… API å¯†é’¥ï¼‰
    # os.environ["OPENAI_API_KEY"] = "your-api-key-here"

    # å¦‚æœä½¿ç”¨ DeepSeek
    # os.environ["OPENAI_API_BASE"] = "https://api.deepseek.com"
    # os.environ["OPENAI_API_KEY"] = "your-deepseek-api-key"

    print("ğŸš€ LangChain MCP å¿«é€Ÿå…¥é—¨\n")

    # 2. è¿æ¥åˆ° MCP æœåŠ¡å™¨
    print("ğŸ“¡ æ­£åœ¨è¿æ¥åˆ° MCP æœåŠ¡å™¨...")
    async with create_mcp_client(
        command="python",
        args=["mcp_server_example.py"],
    ) as client:
        # 3. è·å–æ‰€æœ‰å¯ç”¨å·¥å…·
        tools = await client.list_tools()
        print(f"âœ… æˆåŠŸåŠ è½½ {len(tools)} ä¸ªå·¥å…·\n")

        # æ˜¾ç¤ºå·¥å…·åˆ—è¡¨
        print("ğŸ“‹ å¯ç”¨å·¥å…·:")
        for i, tool in enumerate(tools, 1):
            print(f"   {i}. {tool.name}: {tool.description}")

        # 4. åˆ›å»º LLM
        print("\nğŸ¤– åˆå§‹åŒ– LLM...")
        llm = ChatOpenAI(
            model="gpt-4o-mini",
            temperature=0,
        )

        # 5. åˆ›å»º Agent æç¤ºæ¨¡æ¿
        prompt = ChatPromptTemplate.from_messages(
            [
                ("system", "ä½ æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„åŠ©æ‰‹ï¼Œå¯ä»¥ä½¿ç”¨å·¥å…·æ¥å¸®åŠ©ç”¨æˆ·ã€‚"),
                ("human", "{input}"),
                ("placeholder", "{agent_scratchpad}"),
            ]
        )

        # 6. åˆ›å»º Agent
        agent = create_tool_calling_agent(llm, tools, prompt)
        agent_executor = AgentExecutor(
            agent=agent,
            tools=tools,
            verbose=True,
        )

        # 7. æµ‹è¯•å·¥å…·è°ƒç”¨
        print("\n" + "=" * 60)
        print("å¼€å§‹æµ‹è¯•")
        print("=" * 60 + "\n")

        # æµ‹è¯•é—®é¢˜åˆ—è¡¨
        test_questions = [
            "åŒ—äº¬çš„å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ",
            "è®¡ç®— 25 ä¹˜ä»¥ 48",
            "æŸ¥è¯¢æ•°æ®åº“ä¸­çš„ç”¨æˆ·ä¿¡æ¯",
        ]

        for i, question in enumerate(test_questions, 1):
            print(f"ã€é—®é¢˜ {i}ã€‘{question}")
            response = await agent_executor.ainvoke({"input": question})
            print(f"ã€å›ç­”ã€‘{response['output']}\n")
            print("-" * 60 + "\n")

        print("âœ¨ æµ‹è¯•å®Œæˆï¼")


async def simple_tool_call():
    """ç®€å•çš„å·¥å…·è°ƒç”¨ç¤ºä¾‹ï¼ˆä¸ä½¿ç”¨ Agentï¼‰"""

    print("ğŸ”§ ç›´æ¥è°ƒç”¨å·¥å…·ç¤ºä¾‹\n")

    async with create_mcp_client(
        command="python",
        args=["mcp_server_example.py"],
    ) as client:
        # è·å–å·¥å…·
        tools = await client.list_tools()

        # æŸ¥æ‰¾å¤©æ°”å·¥å…·
        weather_tool = next((t for t in tools if t.name == "get_weather"), None)

        if weather_tool:
            # ç›´æ¥è°ƒç”¨å·¥å…·
            print("è°ƒç”¨å·¥å…·: get_weather")
            result = await weather_tool.ainvoke({"city": "ä¸Šæµ·"})
            print(f"ç»“æœ:\n{result}\n")

        # æŸ¥æ‰¾è®¡ç®—å™¨å·¥å…·
        calc_tool = next((t for t in tools if t.name == "calculator"), None)

        if calc_tool:
            print("è°ƒç”¨å·¥å…·: calculator")
            result = await calc_tool.ainvoke(
                {"operation": "multiply", "a": 12, "b": 34}
            )
            print(f"ç»“æœ:\n{result}\n")


async def interactive_mode():
    """äº¤äº’å¼æ¨¡å¼"""

    print("ğŸ’¬ äº¤äº’å¼æ¨¡å¼ï¼ˆè¾“å…¥ 'quit' æˆ– 'exit' é€€å‡ºï¼‰\n")

    async with create_mcp_client(
        command="python",
        args=["mcp_server_example.py"],
    ) as client:
        tools = await client.list_tools()
        print(f"âœ… åŠ è½½äº† {len(tools)} ä¸ªå·¥å…·\n")

        llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)

        prompt = ChatPromptTemplate.from_messages(
            [
                ("system", "ä½ æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„åŠ©æ‰‹ï¼Œå¯ä»¥ä½¿ç”¨å·¥å…·æ¥å¸®åŠ©ç”¨æˆ·ã€‚"),
                ("human", "{input}"),
                ("placeholder", "{agent_scratchpad}"),
            ]
        )

        agent = create_tool_calling_agent(llm, tools, prompt)
        agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=False)

        # äº¤äº’å¾ªç¯
        while True:
            try:
                user_input = input("ğŸ‘¤ ä½ : ").strip()

                if user_input.lower() in ["quit", "exit", "é€€å‡º"]:
                    print("ğŸ‘‹ å†è§ï¼")
                    break

                if not user_input:
                    continue

                response = await agent_executor.ainvoke({"input": user_input})
                print(f"ğŸ¤– åŠ©æ‰‹: {response['output']}\n")

            except KeyboardInterrupt:
                print("\nğŸ‘‹ å†è§ï¼")
                break
            except Exception as e:
                print(f"âŒ é”™è¯¯: {e}\n")


def main():
    """ä¸»å‡½æ•°"""

    print("""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                                                          â•‘
â•‘  LangChain MCP Adapters - å¿«é€Ÿå…¥é—¨                       â•‘
â•‘                                                          â•‘
â•‘  é€‰æ‹©è¿è¡Œæ¨¡å¼:                                           â•‘
â•‘  1. å¿«é€Ÿå…¥é—¨ç¤ºä¾‹ï¼ˆæ¨èï¼‰                                 â•‘
â•‘  2. ç®€å•å·¥å…·è°ƒç”¨                                         â•‘
â•‘  3. äº¤äº’å¼æ¨¡å¼                                           â•‘
â•‘                                                          â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """)

    # å–æ¶ˆæ³¨é‡Šä¸‹é¢çš„ä»£ç æ¥è¿è¡Œä¸åŒçš„ç¤ºä¾‹

    # è¿è¡Œå¿«é€Ÿå…¥é—¨ç¤ºä¾‹ï¼ˆæ¨èï¼‰
    asyncio.run(quickstart())

    # æˆ–è¿è¡Œç®€å•å·¥å…·è°ƒç”¨
    # asyncio.run(simple_tool_call())

    # æˆ–è¿è¡Œäº¤äº’å¼æ¨¡å¼
    # asyncio.run(interactive_mode())


if __name__ == "__main__":
    main()
